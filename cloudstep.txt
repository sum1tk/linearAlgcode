
1. Install JDK
-Scala requires JDK since it runs on JVM
-Visit Oracle.com and download the  appropriate installer
• Run the installer and follow the prompts to complete the installation.
• Set the JAVA_HOME environment variable to point to your JDK installation
directory.

2.  Download Scala:
• Go to the official Scala website (https://www.scala-lang.org/download/).
• Download the Scala binary for Windows.


3 Install Scala:
• Unzip the downloaded Scala binary to a directory of your choice (e.g., C:\scala).
• Add the Scala bin directory to your system PATH:
----o Right-click on 'This PC' or 'My Computer' and select 'Properties'.
----o Click on 'Advanced system settings'.
----o Click on 'Environment Variables'.
----o Under 'System variables', find and edit 'Path'.
----o Add the path to your Scala bin directory (e.g., C:\scala\bin).

4 Verify the installation:
• Open a new command prompt.
• Type scala -version and press Enter. You should see the Scala version information.

5 Install an Integrated Development Environment (IDE):
• Popular choices include IntelliJ IDEA with the Scala plugin, or Eclipse with the Scala
IDE plugin.
• Download and install your chosen IDE.


1.	Download Spark:
	Go to the Apache Spark website and download the latest version of Spark (choose a pre-built package for Hadoop).
2.	Install Java:
	Ensure Java is installed on your machine. Verify with java -version. If not installed, download and install it from the Oracle website or use OpenJDK.
3.	Extract Spark Files:
	Unzip the downloaded Spark archive to a desired directory.
4.	Set Environment Variables:
	Set the SPARK_HOME environment variable to your Spark directory and add $SPARK_HOME/bin to your system’s PATH variable.
5.	Install Spark Dependencies (Optional):
	If you plan to use Hadoop with Spark, ensure you have Hadoop installed and configured properly.
6.	Run Spark Shell:
	Open a terminal and execute spark-shell to start the interactive shell in local mode.
7.	Verify Installation:
	In the Spark shell, run a simple command (like sc.version) to check if Spark is working correctly.


1. Arithmetic

object Arithmetic{
  def main(args:Array[String]){
    var a=10;
    var b=20;
    //Addition
    println("Addition of a+b = " +(a+b))
    // Subtraction
    println("Subtraction of a-b = " +(a-b))
    // Multiplication
    println("Multiplication of a*b = " +(a*b))
    //Division
    println("Division of a/b = " +(a/b))
    //Modulus
    println("Modulus of a%b = " +(a%b))
    
  }
}

2. Addition of 2 numbers(Rishi)
object Addition{
  def main(args:Array[String]){
    println("Sum is : " + add(5,2))
  }
  def add(a:Int,b:Int):Int={
    var sum:Int=0
    sum=a+b
    sum
  }
}

3. Write a scala program to compute the sum of the two given integer values. If the two
values are the same, then return triple their sum.

object tri{
  def test(x:Int,y:Int):Int={
    if (x==y){
      return (x+y)*3
    } else{
      return x+y
    }
  }
  def main(args:Array[String]):Unit={
    println("Result : " + test(1,2))
    println("Result : " + test(3,3))
  }
}

4. Write a Scala program using for loop to compute the sum of the given two integer
values. If the values are the same, then return triples their sum.

object triloop{
  def test(x:Int,y:Int):Int={
    if (x==y){
      var sum=0
      for(i<-0 to 2){
        sum+=x+y
      }
      return (x+y)*3
    } else{
      return x+y
    }
  }
  def main(args:Array[String]):Unit={
    println("Result : " + test(1,2))
    println("Result : " + test(2,2))
  }
}

5. Write a scala program to print the table of a number

object MultiplicationTable{
  def main(args:Array[String]):Unit={
    val num=6
    val TableSize=10
    println(s"MultiplicationTable of $num is :")
    for(i<-1 to TableSize){
      val product=i*num
      println(s"$num*$i = $product")
    }
  }
}

6. Write a program to greet the user

object greet{
  def greet(name:String="User"):String={
    s"Hello, $name!"
  }
  def main(args:Array[String]):Unit={
    println(greet())
    println(greet("no one"))
  }
}

7. Write a recursive function that calculates the factorial

object recursive{
  def factorial(n:Int):Int={
    if(n==0){
      1
    }
    else n*factorial(n-1)
  }
  def main(args:Array[String]):Unit={
    println("Factorial of 5 is : " +factorial(5))
    }
  }

8. Write a program to print a List

object printlist{
  def printlist(Elements:List[Int]):Unit={
    Elements.foreach(println)
  }
  def main(args:Array[String]):Unit={
    printlist(List(1,2,3,4,5,6,7,8))
  }
}

9. Write a program to add two numbers

object addnumbers{
  def add(a:Int,b:Int):Int={
    a+b
  }
  def main(args:Array[String]):Unit={
    println("3+4="+add(3,4))
  }
}

10. Write a higher order function to apply functions to a list

object higherorder{
  def applytolist(elements:List[Int],f:Int=>Int):List[Int]={
    elements.map(f)
  }
  def main(args:Array[String]):Unit={
    println(applytolist(List(1,2,3,4,5,6),x=>x*x))
  }
}

11. Write an anonymous to filter even numbers

object anonymousfunc{
  def filterevennumbers(numbers:List[Int]):List[Int]={
    numbers.filter(x=>x%2==0)
  }
  def main(args:Array[String]):Unit={
    println(filterevennumbers(List(1,2,3,4,5,6)))
  }
}




change directory to spark bin
run spark-shell
load file val text =sc.textFile(path)
text.collect
val counts = text.flatMap(line => line.split(" "))
val mapf = counts.map(x => (x,1))
mapf.collect
val reduced = mapf.reduceByKey(_ + _)
reduced.collect


